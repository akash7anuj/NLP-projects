{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(r\"Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I always wrote this series off as being a comp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st watched 12/7/2002 - 3 out of 10(Dir-Steve ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This movie was so poorly written and directed ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I always wrote this series off as being a comp...      0\n",
       "1  1st watched 12/7/2002 - 3 out of 10(Dir-Steve ...      0\n",
       "2  This movie was so poorly written and directed ...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "\n",
    "tokenizer = TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_word_english = stopwords.words('english')\n",
    "\n",
    "from string import punctuation\n",
    "\n",
    "extra_word = [\"``\", \"''\" ]\n",
    "\n",
    "stop_word = list(punctuation) + stop_word_english + extra_word\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# and stemmer.stem(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  I always wrote this series off as being a comp...   \n",
      "1  1st watched 12/7/2002 - 3 out of 10(Dir-Steve ...   \n",
      "2  This movie was so poorly written and directed ...   \n",
      "3  The most interesting thing about Miryang (Secr...   \n",
      "4  when i first read about \"berlin am meer\" i did...   \n",
      "\n",
      "                                        cleaned_text  label  \n",
      "0  always wrote series complete jim belushi invol...      0  \n",
      "1  watched purcell typical mary kate ashley fare ...      0  \n",
      "2  movie poorly written directed fell asleep minu...      0  \n",
      "3  interesting thing miryang secret sunshine jeon...      1  \n",
      "4  first read berlin meer expect thought right pe...      0  \n"
     ]
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "         \n",
    "    tokens = tokenizer.tokenize(text.lower())\n",
    "    \n",
    "    # remove stopword and apply lemmatize for root word\n",
    "    cleaned_tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_word and word.isalpha()]\n",
    "    \n",
    "    return ' '.join(cleaned_tokens)\n",
    "\n",
    "\n",
    "dataset['cleaned_text'] = dataset['text'].apply(preprocess_text)\n",
    "\n",
    "print(dataset[['text', 'cleaned_text', 'label']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I always wrote this series off as being a comp...</td>\n",
       "      <td>0</td>\n",
       "      <td>always wrote series complete jim belushi invol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st watched 12/7/2002 - 3 out of 10(Dir-Steve ...</td>\n",
       "      <td>0</td>\n",
       "      <td>watched purcell typical mary kate ashley fare ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This movie was so poorly written and directed ...</td>\n",
       "      <td>0</td>\n",
       "      <td>movie poorly written directed fell asleep minu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  I always wrote this series off as being a comp...      0   \n",
       "1  1st watched 12/7/2002 - 3 out of 10(Dir-Steve ...      0   \n",
       "2  This movie was so poorly written and directed ...      0   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  always wrote series complete jim belushi invol...  \n",
       "1  watched purcell typical mary kate ashley fare ...  \n",
       "2  movie poorly written directed fell asleep minu...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the text data\n",
    "x = vectorizer.fit_transform(dataset['cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "dense_matrix = x.toarray()  \n",
    "print(dense_matrix[:5, :5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 32513)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Get non-zero elements and their indices'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Get non-zero elements and their indices\"\"\"\n",
    "# non_zero_elements = x.nonzero()\n",
    "\n",
    "# # View the non-zero elements and their indices\n",
    "# for row, col in zip(non_zero_elements[0], non_zero_elements[1]):\n",
    "#     print(f\"Document {row}, Term {col} -> TF-IDF: {x[row, col]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dataset[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=6)\n",
    "\n",
    "# 5 for svc\n",
    "# 6 for logisticRegression\n",
    "# 8 for decisiontreeClassifier\n",
    "# 17 for KNeighborsClassifier\n",
    "# 3 for RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Linear': LogisticRegression() ,\n",
    "    'MLP': MLPClassifier(max_iter=500), \n",
    "    'KNeighbors': KNeighborsClassifier(n_neighbors= 41),\n",
    "    'DecisionTree': DecisionTreeClassifier(),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=10),\n",
    "    'svc': SVC(kernel=\"sigmoid\")\n",
    "}\n",
    "\n",
    "\n",
    "lr = LogisticRegression() \n",
    "kn = KNeighborsClassifier(n_neighbors= 41)\n",
    "sv = SVC(kernel=\"sigmoid\")\n",
    "rfc = RandomForestClassifier(n_estimators=10)\n",
    "clf = DecisionTreeClassifier()\n",
    "mlp = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "\n",
    "def classification_error(y_true, y_pred, y_prob=None, average='binary'):\n",
    "    \"\"\"\n",
    "    Compute common classification error metrics.\n",
    "\n",
    "    Parameters:\n",
    "    - y_true: Ground truth target values\n",
    "    - y_pred: Predicted target values\n",
    "    - y_prob: Predicted probabilities (used for AUC)\n",
    "    - average: Defines the type of averaging to be performed on multi-class data.\n",
    "      'binary' for binary classification, 'micro', 'macro', 'weighted', etc., for multi-class.\n",
    "\n",
    "    Returns:\n",
    "    - Dictionary containing various classification metrics\n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "    precision = precision_score(y_true, y_pred, average=average) * 100\n",
    "    recall = recall_score(y_true, y_pred, average=average) * 100\n",
    "    f1 = f1_score(y_true, y_pred, average=average) * 100\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # ROC AUC (Only for binary classification or probability scores)\n",
    "    if y_prob is not None and average == 'binary':\n",
    "        roc_auc = roc_auc_score(y_true, y_prob) * 100\n",
    "    else:\n",
    "        roc_auc = None\n",
    "    \n",
    "    return {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Confusion Matrix': conf_matrix,\n",
    "        'ROC AUC': roc_auc\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear - Train Metrics: {'Accuracy': 94.77142857142857, 'Precision': 94.43820224719101, 'Recall': 95.24079320113314, 'F1 Score': 94.83779971791255, 'Confusion Matrix': array([[1636,   99],\n",
      "       [  84, 1681]], dtype=int64), 'ROC AUC': None}\n",
      "Linear - Test Metrics: {'Accuracy': 85.0, 'Precision': 81.75092478421702, 'Recall': 89.5945945945946, 'F1 Score': 85.49323017408123, 'Confusion Matrix': array([[612, 148],\n",
      "       [ 77, 663]], dtype=int64), 'ROC AUC': None}\n",
      "\n",
      "MLP - Train Metrics: {'Accuracy': 100.0, 'Precision': 100.0, 'Recall': 100.0, 'F1 Score': 100.0, 'Confusion Matrix': array([[1735,    0],\n",
      "       [   0, 1765]], dtype=int64), 'ROC AUC': None}\n",
      "MLP - Test Metrics: {'Accuracy': 83.86666666666667, 'Precision': 83.0238726790451, 'Recall': 84.5945945945946, 'F1 Score': 83.80187416331995, 'Confusion Matrix': array([[632, 128],\n",
      "       [114, 626]], dtype=int64), 'ROC AUC': None}\n",
      "\n",
      "KNeighbors - Train Metrics: {'Accuracy': 75.68571428571428, 'Precision': 85.20801232665639, 'Recall': 62.6628895184136, 'F1 Score': 72.2167809337251, 'Confusion Matrix': array([[1543,  192],\n",
      "       [ 659, 1106]], dtype=int64), 'ROC AUC': None}\n",
      "KNeighbors - Test Metrics: {'Accuracy': 74.2, 'Precision': 81.91681735985533, 'Recall': 61.21621621621621, 'F1 Score': 70.06960556844548, 'Confusion Matrix': array([[660, 100],\n",
      "       [287, 453]], dtype=int64), 'ROC AUC': None}\n",
      "\n",
      "DecisionTree - Train Metrics: {'Accuracy': 100.0, 'Precision': 100.0, 'Recall': 100.0, 'F1 Score': 100.0, 'Confusion Matrix': array([[1735,    0],\n",
      "       [   0, 1765]], dtype=int64), 'ROC AUC': None}\n",
      "DecisionTree - Test Metrics: {'Accuracy': 65.66666666666666, 'Precision': 64.98002663115847, 'Recall': 65.94594594594595, 'F1 Score': 65.45942320590208, 'Confusion Matrix': array([[497, 263],\n",
      "       [252, 488]], dtype=int64), 'ROC AUC': None}\n",
      "\n",
      "RandomForest - Train Metrics: {'Accuracy': 99.22857142857143, 'Precision': 99.54389965792474, 'Recall': 98.92351274787535, 'F1 Score': 99.23273657289002, 'Confusion Matrix': array([[1727,    8],\n",
      "       [  19, 1746]], dtype=int64), 'ROC AUC': None}\n",
      "RandomForest - Test Metrics: {'Accuracy': 74.66666666666667, 'Precision': 77.4390243902439, 'Recall': 68.64864864864865, 'F1 Score': 72.77936962750717, 'Confusion Matrix': array([[612, 148],\n",
      "       [232, 508]], dtype=int64), 'ROC AUC': None}\n",
      "\n",
      "svc - Train Metrics: {'Accuracy': 95.94285714285714, 'Precision': 95.61551433389545, 'Recall': 96.37393767705382, 'F1 Score': 95.99322799097065, 'Confusion Matrix': array([[1657,   78],\n",
      "       [  64, 1701]], dtype=int64), 'ROC AUC': None}\n",
      "svc - Test Metrics: {'Accuracy': 85.53333333333333, 'Precision': 83.56867779204109, 'Recall': 87.97297297297297, 'F1 Score': 85.71428571428571, 'Confusion Matrix': array([[632, 128],\n",
      "       [ 89, 651]], dtype=int64), 'ROC AUC': None}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop through each model\n",
    "for name, model in models.items():\n",
    "    \n",
    "    # Fit the model to the training data\n",
    "    model.fit(x_train, y_train)\n",
    "      \n",
    "    # Predict on training and test data\n",
    "    train_predictions = model.predict(x_train)\n",
    "    test_predictions = model.predict(x_test)\n",
    "\n",
    "    # Get the classification error metrics for both training and test sets\n",
    "    train_metrics = classification_error(y_train, train_predictions)\n",
    "    test_metrics = classification_error(y_test, test_predictions)  \n",
    "\n",
    "    # Print the metrics\n",
    "    print(f\"{name} - Train Metrics: {train_metrics}\")\n",
    "    print(f\"{name} - Test Metrics: {test_metrics}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85.0, 94.77142857142857)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression() \n",
    "\n",
    "cv_scores = cross_val_score(lr, x_train, y_train, cv=7)\n",
    "\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "lr.score(x_test, y_test)*100  , lr.score(x_train, y_train)*100\n",
    "\n",
    "# overfitting = train > test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([84.8, 84.8, 85. , 85.6, 78.8, 84. , 85.8]), 84.1142857142857)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores*100, np.mean(cv_scores) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([85.42857143, 86.        , 81.71428571, 82.85714286, 81.85714286]),\n",
       " 83.57142857142857,\n",
       " 1.8024926052099988)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "\n",
    "lr = LogisticRegression() \n",
    "\n",
    "# cv_scores = cross_val_score(lr, x_train, y_train, cv=7)\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "cv_scores = cross_val_score(lr, x_train, y_train, cv=kf, scoring='accuracy')\n",
    "\n",
    "cv_scores*100, cv_scores.mean()*100,  cv_scores.std()*100\n",
    "\n",
    "# overfitting = train > test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[612, 148],\n",
       "       [ 77, 663]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm2 = confusion_matrix(y_test, lr.predict(x_test))\n",
    "cm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.81      0.84       760\n",
      "           1       0.82      0.90      0.85       740\n",
      "\n",
      "    accuracy                           0.85      1500\n",
      "   macro avg       0.85      0.85      0.85      1500\n",
      "weighted avg       0.85      0.85      0.85      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = lr.predict(x_test)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# assemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84.46666666666667, 93.82857142857142)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "base_model = LogisticRegression()\n",
    "\n",
    "bag_model = BaggingClassifier(estimator= base_model, n_estimators= 50, random_state= 42, )\n",
    "\n",
    "cv_scores = cross_val_score(bag_model, x_train, y_train, cv=7)\n",
    "\n",
    "bag_model.fit(x_train, y_train)\n",
    "\n",
    "bag_model.score(x_test, y_test)*100  , bag_model.score(x_train, y_train)*100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(73.86666666666667, 78.48571428571428)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "base_model = lr = LogisticRegression()\n",
    "\n",
    "bag_model = AdaBoostClassifier(estimator= base_model, n_estimators= 50, random_state= 42, )\n",
    "\n",
    "cv_scores = cross_val_score(bag_model, x_train, y_train, cv=7)\n",
    "\n",
    "bag_model.fit(x_train, y_train)\n",
    "\n",
    "bag_model.score(x_test, y_test)*100  , bag_model.score(x_train, y_train)*100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85.0, 99.77142857142857)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "base_modal = [\n",
    "    ('decision_tree', DecisionTreeClassifier()),\n",
    "    ('svc', SVC(probability= True))\n",
    "]\n",
    "\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "stack_model = StackingClassifier(estimators= base_modal, final_estimator= meta_model)\n",
    "\n",
    "stack_model.fit(x_train, y_train)\n",
    "\n",
    "stack_model.score(x_test, y_test)*100  , stack_model.score(x_train, y_train)*100\n",
    "\n",
    "# 85.0666,  99.771428\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# param_lr = {\n",
    "#     'max_iter': [100, 200, 500],  # Number of features to select\n",
    "#     'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "#     'penalty': ['l1', 'l2', 'elasticnet'],  # Regularization types\n",
    "#     'solver': ['saga', 'liblinear', 'sag', 'lbfgs'],  # Solvers\n",
    "#     'multi_class': ['auto', 'ovr', 'multinomial']\n",
    "\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(estimator= lr, param_grid= param_lr, cv=2, verbose=1, n_jobs=-1)\n",
    "\n",
    "# grid_search.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# best_params = grid_search.best_params_\n",
    "# best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in np.arange(0.01, 1.0, 0.01):\n",
    "    \n",
    "#     lr = LogisticRegression(C=i)\n",
    "#     lr.fit(x_train, y_train)\n",
    "#     knp = lr.score(x_test, y_test)*100\n",
    "#     knp1 = lr.score(x_train, y_train)*100\n",
    "    \n",
    "#     print(knp, knp1, {knp1 - knp}, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1, 70):\n",
    "#     x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=i)\n",
    "#     lr = LogisticRegression()\n",
    "#     lr.fit(x_train, y_train)\n",
    "#     knp = lr.score(x_test, y_test)*100\n",
    "#     knp1 = lr.score(x_train, y_train)*100\n",
    "    \n",
    "#     print(knp, knp1, {knp1 - knp}, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check the model output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vr = VotingClassifier\n",
    "\n",
    "lr = logisticRegression\n",
    "rfc = RandomForestClassifier\n",
    "sv = SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This LogisticRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m test_texts_transformed \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mtransform(test_texts)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mlr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_texts_transformed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Display the predictions\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text, prediction \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(test_texts, predictions):\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:382\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    381\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 382\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    384\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, indexing_dtype(xp))\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:360\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    342\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;124;03m    Predict confidence scores for samples.\u001b[39;00m\n\u001b[0;32m    344\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;124;03m        this class would be predicted.\u001b[39;00m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 360\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    361\u001b[0m     xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m    363\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:1661\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1658\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[0;32m   1660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[1;32m-> 1661\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This LogisticRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "# Test on new examples\n",
    "test_texts = [\n",
    "    \"I enjoy during sunny days\",\n",
    "    \"I hate coding errors\",\n",
    "    \"This man is bad\",\n",
    "    \"your rice is nice\",\n",
    "    \"anuj is good boy\",\n",
    "]\n",
    "\n",
    "test_texts_transformed = vectorizer.transform(test_texts)\n",
    "\n",
    "# Make predictions\n",
    "predictions = lr.predict(test_texts_transformed)\n",
    "\n",
    "# Display the predictions\n",
    "for text, prediction in zip(test_texts, predictions):\n",
    "    print(f\"Text: '{text}' - Prediction: {'Positive' if prediction == 1 else 'Negative'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
