{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP\n",
    "      type of NLP\n",
    "\n",
    "      1. NLU   { understand the }\n",
    "      2. NLG\n",
    "\n",
    "**NLTK** library for NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Challenges\n",
    "\n",
    "1. Contextual words and phrases and homonyms\n",
    "2. Synonyms\n",
    "3. Irony and sarcasm\n",
    "4. Ambiguity\n",
    "5. Errors in text or speech\n",
    "6. Colloquialisms and slang\n",
    "7. Domain-specific language\n",
    "8. Low-resource languages\n",
    "9. Lack of research and development"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data collection -> Text Cleaning -> Pre-processing -> Feature Engineering -> Modeling -> Evalution -> Deployment -> Monitoring & update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Pre-processing\n",
    "\n",
    "***Text Cleaning***: In-text cleaning we do HTML tag removing, emoji handling, Spelling checker, etc.\n",
    "\n",
    "***Basic Preprocessing***: In basic preprocessing we do tokenization (word or sent tokenization, stop word removal, removing digit, lower casing.) Â  \n",
    "\n",
    "***Advance Preprocessing***: In this step we do POS tagging, Parsing, and Coreference resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featured Engineering\n",
    "\n",
    "1. One Hot Encoder\n",
    "2. Bag Of Word(BOW)\n",
    "3. n-grams\n",
    "4. Tf-Idf\n",
    "5. Word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling/Model Building\n",
    "\n",
    "***Approaches to building model***:\n",
    "\n",
    "1. Heuristic Approach   { manual work & manual programing }\n",
    "2. Machine Learning Approach\n",
    "3. Deep Learning Approach\n",
    "4. Cloud API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "***Intrinsic evaluation***: In this evaluation, we use multiple metrics to check our model such as Accuracy, Recall, Confusion Metrics, Perplexity, etc.\n",
    "\n",
    "***Extrinsic evaluation***: This evaluation is done after deployment. This is the business-centric approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Textual Data\n",
    "***Elements of Text***:\n",
    "\n",
    "1. Hierarchy of Text  [counting] [ no. of words & no. of alphabet ]\n",
    "2. Tokens [converting into numbers ] \n",
    "3. Vocabulary\n",
    "4. Punctuation  [ no. of \",\" or \".\" etc ]\n",
    "5. Part of speech\n",
    "6. Root of a word\n",
    "7. Base of a word\n",
    "8. Stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Text Pre-processing Techniques***\n",
    "\n",
    "**formatting**\n",
    "1. Lowercasing\n",
    "2. Remove HTML Tags\n",
    "3. Remove URLs\n",
    "4. Removing Punctuation\n",
    "5. Chat word Treatment\n",
    "6. Spelling Correction\n",
    "\n",
    "\n",
    "7. Tokenization\n",
    "8. Stop words removal\n",
    "9. N-Grams\n",
    "10. Stemming\n",
    "11. Word Sense Disambiguation\n",
    "12. Count Vectorizer\n",
    "13. Lemmatization\n",
    "14. TF-IDF Vectorization\n",
    "15. Hashing Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
